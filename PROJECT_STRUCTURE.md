# Tensorax - Project Structure

## ğŸ“¦ Directory Tree

```
tensorax/
â”œâ”€â”€ ğŸ“„ README.md                      # Main project documentation
â”œâ”€â”€ ğŸ“„ LICENSE                        # MIT License
â”œâ”€â”€ ğŸ“„ setup.py                       # Build configuration
â”œâ”€â”€ ğŸ“„ pyproject.toml                 # Python project metadata
â”œâ”€â”€ ğŸ“„ MANIFEST.in                    # Package manifest
â”œâ”€â”€ ğŸ“„ requirements.txt               # Runtime dependencies (pybind11)
â”œâ”€â”€ ğŸ“„ requirements-dev.txt           # Development dependencies
â”œâ”€â”€ ğŸ“„ .gitignore                     # Git ignore rules
â”œâ”€â”€ ğŸ”§ build.sh                       # Quick build script
â”œâ”€â”€ ğŸ“„ demo.py                        # Comprehensive demo script
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md           # This file
â”œâ”€â”€ ğŸ“„ REFACTORING_SUMMARY.md         # NumPy removal summary
â”‚
â”œâ”€â”€ ğŸ“ csrc/                          # C++ and CUDA source code
â”‚   â”œâ”€â”€ ğŸ“„ tensor_ops.h              # Operation declarations
â”‚   â”œâ”€â”€ ğŸ“„ tensor_ops.cpp            # Python bindings (pybind11)
â”‚   â”œâ”€â”€ ğŸ“ cpu/                      # CPU implementations
â”‚   â”‚   â””â”€â”€ ğŸ“„ tensor_cpu.cpp       # CPU operations (add, mul, matmul, etc.)
â”‚   â””â”€â”€ ğŸ“ cuda/                     # CUDA implementations
â”‚       â”œâ”€â”€ ğŸ“„ cuda_utils.cuh        # CUDA utilities and macros
â”‚       â”œâ”€â”€ ğŸ“„ tensor_cuda.cu        # CUDA memory management
â”‚       â””â”€â”€ ğŸ“ kernels/              # Optimized CUDA kernels
â”‚           â”œâ”€â”€ ğŸ“„ elementwise.cu    # Element-wise ops (add, mul, sqrt, etc.)
â”‚           â”œâ”€â”€ ğŸ“„ reduction.cu      # Reduction ops (sum, max, etc.)
â”‚           â””â”€â”€ ğŸ“„ matmul.cu         # Tiled matrix multiplication
â”‚
â”œâ”€â”€ ğŸ“ tensorax/                       # Python package
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py               # Package initialization
â”‚   â”œâ”€â”€ ğŸ“„ tensor.py                 # Core Tensor class with autograd
â”‚   â”œâ”€â”€ ğŸ“„ functional.py             # Functional API (F.relu, losses, etc.)
â”‚   â”œâ”€â”€ ğŸ“„ optim.py                  # Optimizers (SGD, Adam)
â”‚   â””â”€â”€ ğŸ“ nn/                       # Neural network modules
â”‚       â”œâ”€â”€ ğŸ“„ __init__.py
â”‚       â”œâ”€â”€ ğŸ“„ module.py             # Base Module class
â”‚       â””â”€â”€ ğŸ“„ layers.py             # Layers (Linear, ReLU, Sequential, etc.)
â”‚
â”œâ”€â”€ ğŸ“ tests/                         # Test suite
â”‚   â”œâ”€â”€ ğŸ“„ __init__.py
â”‚   â”œâ”€â”€ ğŸ“„ test_tensor.py            # Tensor operation tests
â”‚   â”œâ”€â”€ ğŸ“„ test_nn.py                # Neural network tests
â”‚   â”œâ”€â”€ ğŸ“„ test_optim.py             # Optimizer tests
â”‚   â””â”€â”€ ğŸ“„ test_functional.py        # Functional API tests
â”‚
â”œâ”€â”€ ğŸ“ examples/                      # Usage examples
â”‚   â”œâ”€â”€ ğŸ“„ README.md
â”‚   â”œâ”€â”€ ğŸ“„ basic_operations.py       # Basic tensor ops demo
â”‚   â”œâ”€â”€ ğŸ“„ simple_nn.py              # Neural network example
â”‚   â””â”€â”€ ğŸ“„ cuda_example.py           # GPU acceleration demo
â”‚
â””â”€â”€ ğŸ“ docs/                          # Documentation
    â”œâ”€â”€ ğŸ“„ ARCHITECTURE.md           # System architecture details
    â”œâ”€â”€ ğŸ“„ DEVELOPMENT.md            # Development workflow
    â””â”€â”€ ğŸ“„ GUIDE.md                  # Complete development roadmap
```

## ğŸ¯ Key Components

### 1. C++/CUDA Backend (csrc/)

**Purpose**: High-performance tensor operations with zero PyTorch/NumPy dependency

**Key Files**:

- `tensor_ops.cpp`: Python bindings using pybind11, high-level operation wrappers
- `tensor_ops.h`: Operation declarations and TensorImpl class
- `cuda/kernels/*.cu`: Optimized CUDA kernels
- `cpu/tensor_cpu.cpp`: CPU fallback implementations

**Operations Fully Implemented**:

- **Element-wise**: add, subtract, multiply, divide, sqrt
- **Matrix**: matmul (tiled CUDA algorithm with 448x speedup), transpose
- **Activations**: ReLU, sigmoid, tanh, softmax
- **Losses**: MSE, cross-entropy
- **Utilities**: random normal distribution, device transfers (CPUâ†”CUDA)

### 2. Python API (tensorax/)

**Purpose**: User-friendly PyTorch-like interface with automatic differentiation

**Key Classes**:

- `Tensor`: Core multi-dimensional array with full autograd support
  - Operations: `+`, `-`, `*`, `/`, `@` (matmul)
  - Properties: `.T` (transpose), `.shape`, `.device`, `.requires_grad`
  - Methods: `.backward()`, `.zero_grad()`, `.sqrt()`, `.cuda()`, `.cpu()`
  - Factory methods: `.zeros()`, `.ones()`, `.full()`, `.randn()`
- `Module`: Base class for neural network layers
  - Parameter management
  - Device transfer support
- `Optimizer`: Base class for optimization algorithms
  - Parameter updates with gradient descent

**Neural Network Modules** (`nn/`):

- `Linear`: Fully connected layer with Xavier initialization
- `ReLU/Sigmoid/Tanh`: Activation layers
- `Sequential`: Layer container accepting list or varargs

**Optimizers** (`optim.py`):

- `SGD`: Stochastic Gradient Descent with momentum support
- `Adam`: Adaptive moment estimation with bias correction

### 3. Functional API (tensorax/functional.py)

**Purpose**: Stateless operations for functional programming style

**Functions**:

- **Activations**: `relu()`, `sigmoid()`, `tanh()`, `softmax()`
- **Losses**: `mse_loss()`, `cross_entropy_loss()`
- **Operations**: `linear()`

### 4. Automatic Differentiation

**Complete backpropagation system** supporting:

- All arithmetic operations (`+`, `-`, `*`, `/`)
- Matrix operations (matmul, transpose)
- Activation functions (ReLU, sigmoid, tanh)
- Loss functions (MSE)
- Gradient accumulation and parameter updates

**Gradient flow** tracked through computational graph with proper chain rule application.

### 5. Tests (tests/)

**Test Coverage**:

- Tensor operations and device transfers
- Gradient computation and backpropagation
- Layer functionality
- Optimizer behavior (SGD with momentum, Adam)
- Functional API

### 6. Documentation (docs/)

- **ARCHITECTURE.md**: System design, memory management, kernel design
- **DEVELOPMENT.md**: Build process, testing, debugging
- **GUIDE.md**: Complete development roadmap

## ğŸš€ Quick Start

### Requirements

- Python 3.8+
- C++17 compiler (g++ or clang++)
- CUDA Toolkit 11.0+ (optional, for GPU support)
- pybind11 (automatically installed)

### Installation

```bash
# Clone repository
git clone https://github.com/NotShrirang/tensorax.git
cd tensorax

# Quick build (automatically detects CUDA)
bash build.sh

# Install in development mode
pip install -e .
```

### Run Demo

```bash
# Comprehensive demonstration of all features
python demo.py
```

### Test

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=tensorax --cov-report=html
```

### Examples

```bash
# Basic operations
python examples/basic_operations.py

# Neural network
python examples/simple_nn.py

# CUDA demo (requires GPU)
python examples/cuda_example.py
```

## ğŸ“Š Implementation Status

### âœ… Completed

- [x] Project structure and build system
- [x] Basic tensor operations (CPU/CUDA)
- [x] Tensor class with device management
- [x] Module system for neural networks
- [x] Common layers (Linear, activations)
- [x] Optimizers (SGD, Adam)
- [x] Test infrastructure
- [x] Documentation and examples

### ğŸš§ To Implement (See GUIDE.md for details)

- [ ] Complete autograd system
- [ ] Convolution and pooling layers
- [ ] More reduction operations
- [ ] Batch normalization
- [ ] Learning rate schedulers
- [ ] Model serialization
- [ ] Multi-GPU support
- [ ] Mixed precision training

## ğŸ”§ Build System

### Dependencies

**Runtime**:

- Python 3.8+
- NumPy
- PyTorch (for build utilities only)

**Build**:

- C++17 compiler
- pybind11
- CUDA Toolkit 11.0+ (optional)

### Configuration

- `setup.py`: Main build script
- `pyproject.toml`: Modern Python packaging
- `MANIFEST.in`: Files to include in distribution

### CUDA Support

Automatically detected via `CUDA_HOME` environment variable.
Falls back to CPU-only if CUDA not available.

## ğŸ“š Learning Resources

### For CUDA Development

1. CUDA C Programming Guide
2. CUDA Best Practices Guide
3. Nsight Compute/Systems profiling tools

### For Deep Learning

1. PyTorch source code (reference implementation)
2. CS231n course (Stanford)
3. Deep Learning book (Goodfellow et al.)

### Similar Projects to Study

- PyTorch
- TinyGrad
- JAX
- Tinygrad

## ğŸ¤ Contributing

See `docs/DEVELOPMENT.md` for:

- Development environment setup
- Code style guidelines
- Testing procedures
- Pull request process

## ğŸ“ˆ Performance Tips

### CUDA Optimization

1. Use tiled algorithms for matrix ops
2. Maximize shared memory usage
3. Ensure coalesced memory access
4. Profile with Nsight Compute
5. Consider kernel fusion

### Python Optimization

1. Minimize Python/C++ boundary crossings
2. Batch operations when possible
3. Use NumPy vectorization
4. Consider Cython for critical paths

## ğŸ› Common Issues

### Build Errors

- Check CUDA_HOME is set correctly
- Verify C++ compiler supports C++17
- Ensure pybind11 is installed

### Runtime Errors

- Check CUDA availability with `cuda_is_available()`
- Verify tensor devices match for operations
- Check array shapes for broadcasting

### Memory Issues

- CUDA memory leaks: Check cudaFree calls
- CPU memory: Let Python GC handle it
- Use smaller batch sizes if OOM

## ğŸ“ Support

- **Issues**: GitHub Issues
- **Discussions**: GitHub Discussions
- **Documentation**: docs/ directory
- **Examples**: examples/ directory

---

**Next Steps**: Follow the development roadmap in `docs/GUIDE.md` to implement remaining features!
